{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Информационные технологии (ML)\n",
    "\n",
    "## Семинар 2\n",
    "\n",
    "## Работа с табличными данными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В машинном обучении, как правило, всё сводится к анализу табличных данных. Начинать мы можем с большого количества сложных таблиц, изображений, текстов или ещё чего-то непростого, но в итоге всё это обычно сводится к одной таблице, где каждый объект описывается набором признаков. Поэтому важно уметь работать с таблицами.\n",
    "\n",
    "А ещё есть некоторые исследования, показывающие, что в решении задачи интеллектуального анализа данных обычно 20% времени уходит на построение моделей и прочую интересную работу, связанную с тем, что рассказывается у нас на лекциях, а 80% времени специалисты тратят на подготовку и обработку данных. Сюда входит формирование признаков, устранение выбросов и пропусков и т.д. И это тоже, по сути дела, манипуляции с таблицами.\n",
    "\n",
    "Вывод: важно уметь работать с табличными данными. В Python для этого есть библиотека pandas, которую мы и будем сегодня изучать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чаще всего название библиотеки при импорте сокращают до \"pd\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Распределение студентов по элективам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разумно тренироваться на реальных сложных данных. А что может быть более сложным, чем данные, сгенерированные студентами?\n",
    "\n",
    "Сегодня мы будем работать с анкетами студентов 2017 и 2018 годов набора о том, на какие курсы по выбору они хотят попасть. Данные были анонимизированы: ФИО захешированы, к рейтингам добавлен случайный шум.\n",
    "\n",
    "*Вопрос: как можно деанонимизировать данные после манипуляций, которые мы проделали? А как бы вы предложили провести анонимизацию?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас есть 2 таблицы (для 3 и 4 курса):\n",
    "\n",
    "    – 'Timestamp': время получения ответов\n",
    "    – 'ID': ID студента (может повторяться, если студент больше одного раза заполнял анкету) \n",
    "    – 'Рейтинг': Кредитно-рейтинговая сумма студента (грубо говоря, сумма оценок студента по всем его дисциплинам с весами — чем дольша шла дисциплина, тем больше вес; подробности тут: https://www.hse.ru/studyspravka/rate/)\n",
    "    – 'Группа (в формате 182)': Номер группы\n",
    "    – 'МИ?': 1, если студент распределился на специализацию МИ, или NaN в противном случае (признак важен, поскольку студенты МИ берут осенью два курса по выбору, а студенты остальных специализаций только один)\n",
    "    – 'Осенний курс по выбору, приоритет 1'\n",
    "    – 'Осенний курс по выбору, приоритет 2' \n",
    "    – 'Осенний курс по выбору, приоритет 3'\n",
    "    – 'Весенний курс по выбору, приоритет 1'\n",
    "    – 'Весенний курс по выбору, приоритет 2'\n",
    "    – 'Весенний курс по выбору, приоритет 3'\n",
    "    – 'Вы заполняете анкету в первый раз?': \"Да\" или \"Нет\"\n",
    "   \n",
    "Дополнительные столбцы для 4ого курса:\n",
    "    \n",
    "    – 'Группа (в формате 173)': Номер группы\n",
    "    – 'blended-курс': Выбор blended-курса (кол-во мест неограничено)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные (обратите внимание, что мы легко читаем xlsx-файлы):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = pd.read_excel('data_3_course.xlsx')\n",
    "data4 = pd.read_excel('data_4_course.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим размер таблицы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала будем работать с одной таблицей для 3 курса. Теперь данные хранятся в переменной ```data3```, которая имеет тип [DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame можно создать и вручную:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'AAA' : [4,5,6,7], \n",
    "                   'BBB' : [10,20,30,40], \n",
    "                   'CCC' : [100,50,'E',-50]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame можно частично отобразить в jupyter-ноутбуке с помощью методов ```head```(первые строки) и ```sample```(случайные строки):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно немного залезть во внутренности Jupyter, чтобы отобразить сразу несколько таблиц:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "display(data3.sample(3)), display(data3.sample(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вам очень хочется отобразить все строки таблицы, то можно сделать так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.max_rows = 999\n",
    "# data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame, по сути, является двумерной таблицей с набором полезных методов. Давайте рассмотрим некоторые из них.\n",
    "\n",
    "```columns``` — возвращает названия колонок\n",
    "\n",
    "```dtypes``` — типы колонок\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data3.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В DataFrame есть несколько способов для обращения к строкам, столбцам и отдельным элементам таблицы: квадратные скобки и методы ```loc```, ```iloc```.\n",
    "\n",
    "Как обычно, лучший источник знаний об этом — [документация](https://pandas.pydata.org/docs/user_guide/indexing.html).\n",
    "Ниже краткое содержание."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В метод ```loc``` можно передать значение индекса (число, которое стоит в колонке index) строки, чтобы получить эту строку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.loc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили отдельную строчку в виде объекта класса [Series](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data3.loc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А с помощью срезов можно выбрать часть таблицы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.loc[2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Срез в ```loc``` производится по index и включает в себя последний элемент.\n",
    "\n",
    "Метод ```iloc``` действует похожим образом, но он индексирует элементы не по index, а по порядку в таблице (который может отличаться от index). Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = data3.sample(5)\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если же вызвать просто ```loc```[2], то получим ошибку:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset.loc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью ```iloc``` тоже можно делать срезы, но в них последний элемент не включается (как и в обычных срезах в Python, **в отличие от loc**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.iloc[2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Срезы можно брать не только по строкам, но и по столбцам. Обратите внимание на различия индексации столбцов в ```loc``` и ```iloc```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.iloc[2:4,2:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.loc[2:4, 'Рейтинг':'Осенний курс по выбору, приоритет 1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Через квадратные скобки можно обращаться к одной или нескольким колонкам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3['Рейтинг'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3[['Рейтинг', 'Осенний курс по выбору, приоритет 1']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть и более интересные способы индексации. Например, давайте выберем студентов из группы 182:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3[data3['Группа (в формате 182)'] == 182].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С DataFrame'ами и Series'ами одинаковой структуры можно производить математические операции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strange_feature = data3['Рейтинг'] ** 2 + data3['Группа (в формате 182)']\n",
    "# strange_feature.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видимо, 'Рейтинг' представлен в виде строки. Исправим это:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data3['Рейтинг'].apply(lambda x: float(str(x).replace(',', '.')))\n",
    "\n",
    "# strange_feature = data3['Рейтинг'] ** 2 + data3['Группа (в формате 182)']\n",
    "# strange_feature.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем ту же ошибку, ведь метод apply не модифицирует таблицу, а просто возвращает новый столбец. Обходят это обычно так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data3['Рейтинг'] = data3['Рейтинг'].apply(lambda x: float(str(x).replace(',', '.')))\n",
    "\n",
    "strange_feature = data3['Рейтинг'] ** 2 + data3['Группа (в формате 182)']\n",
    "strange_feature.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В дальнейшем нам понадобится работать с перцентилями студентов. Чтобы сделать такой столбец, в pandas уже есть подходящий метод:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3['percentile'] = data3['Рейтинг'].rank() / data3.shape[0]\n",
    "\n",
    "# добавим также наш странный признак\n",
    "data3['new'] = strange_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При желании можно удалить любой признак при помоши метода ```drop```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data3.drop(columns=['new'])\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разведочный анализ\n",
    "\n",
    "Теперь изучим наши данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала посмотрим еще раз на типы данных и подумаем, надо ли их менять:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вроде бы нет... \n",
    "\n",
    "А что с таблицей для 4ого курса? Как вы знаете, на ряд курсов студенты 3 и 4 годов обучения отбираются совместно, поэтому надо собрать данные в одну таблицу. *Можно ли это сделать без подготовки?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется, рейтинги имеют разные распределения. Проверим это:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3['Рейтинг'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4['Рейтинг'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да, рейтинг для 4 курса тоже надо привести к числовому типу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4['Рейтинг'] = data4['Рейтинг'].apply(lambda x: float(str(x).replace(',', '.')))\n",
    "data4['Рейтинг'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что квантили в самом деле отличаются — поэтому сами рейтинги не стоит использовать после объединения таблиц, надо работать только с перцентилями. Вычислим их и объединим таблицы с помощью метода ```concat```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4['percentile'] = data4['Рейтинг'].rank() / data4.shape[0]\n",
    "\n",
    "\n",
    "data = pd.concat([data3, data4])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь для удобства переименуем столбцы (обратите внимание на ```inplace=True```):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'Timestamp':'timestamp',\n",
    "                     'ID':'id',\n",
    "                     'Рейтинг':'rating',\n",
    "                     'МИ?':'is_mi',\n",
    "                     'Группа (в формате 182)':'18_group',\n",
    "                     'Группа (в формате 173)':'17_group',\n",
    "                     'Осенний курс по выбору, приоритет 1':'fall_1',\n",
    "                     'Осенний курс по выбору, приоритет 2':'fall_2',\n",
    "                     'Осенний курс по выбору, приоритет 3':'fall_3',\n",
    "                     'Весенний курс по выбору, приоритет 1':'spring_1',\n",
    "                     'Весенний курс по выбору, приоритет 2':'spring_2',\n",
    "                     'Весенний курс по выбору, приоритет 3':'spring_3',\n",
    "                     'Вы заполняете анкету в первый раз?':'is_first_time',\n",
    "                     'blended-курс':'blended'},\n",
    "           inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку у (почти всех) столбцов теперь названия являются корректными именами переменных в Python, мы можем использовать ещё один способ обращения к столбцам таблицы как к полям класса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fall_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нередко работы с данными начинают с поиска пропущенных значений (NaN и др.) и их заполнения. Для начала посмотрим на их наличие:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что тут содержательных пропусков нет — есть только проблемы с колонками, специфичными для одного из курсов.\n",
    "\n",
    "Заполнять пропуски необходимо в соответствии со смыслом колонки. Можно заполнять с помощью среднего, медианного, константного или других значений. Для этого обычно используется метод ```fillna()``` с которым вы познакомитесь в домашнем задании."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также для разведочного анализа может помочь метод ```groupby(column)```. \n",
    "\n",
    "Он группирует объекты по указанной(-ым) колонке(-ам). Необходимо также указать какую статистику для группировки выводить. Это может быть количество (count), среднее (mean) или другие. Из огромной функциональности этого метода разберем только несколько базовых приемов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('fall_1').count()[['id', 'is_mi']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Какие выводы вы можете сделать отсюда?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем ```groupby``` с усреднением:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(by='fall_1').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отсюда мы узнаём среднюю перцентиль для того или иного курса по выбору.\n",
    "Обратите внимание, что средний рейтинг тут не очень показателен из-за разных его распределений у разных годов обучения.\n",
    "\n",
    "Что выводится в следующей строке?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(by='fall_1').count()[['17_group', '18_group']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полезным бывает посмотреть на основные статистики по каждому *числовому*  признаку (столбцу). Метод ```describe``` позволяет быстро сделать это: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Какие элементы таблицы выше могут быть полезны? Для чего?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Студентам специализации МОП (машинное обучение и приложения) нельзя выбирать курс \"Машинное обучение 2\" в качестве весеннего курса по выбору. Давайте проверим, есть ли те, кто попытался:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_students = pd.read_excel('ml_students_anon.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы знакомы с SQL, то знаете, что там крайне часто используется операция JOIN для соединения нескольких таблиц по тому или иному значению. В pandas такое тоже есть, функция называется ```merge```.\n",
    "\n",
    "У нас есть две таблицы: (1) приоритеты студентов по элективам и (2) специализации, на которые распределены студенты. Эти таблицы содержат разную информацию про студентов, но в обеих конкретный студент имеет один и тот же ID. Допустим, мы теперь хотим соединить эти таблицы — то есть получить новую таблицу, в которой для каждого студента есть информация и о приоритетах по элективам, и о его специализации. Как раз для этого и понадобится операция ```merge```.\n",
    "\n",
    "Идея соединения таблиц также отражена на картинке ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/WYyBFTE.png\" style=\"width: 400px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(ml_students, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['is_ml_student'] == True) & \n",
    "     (\n",
    "         (data['spring_1'] == 'Машинное обучение 2')\n",
    "         |\n",
    "         (data['spring_2'] == 'Машинное обучение 2')\n",
    "         |\n",
    "         (data['spring_3'] == 'Машинное обучение 2')\n",
    "     )] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем понять, есть ли явная зависимость между рейтингом и номером группы. Для начала посмотрим на корреляции (функция corr считает по умолчанию корреляцию Пирсона):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = data[['rating', '18_group', '17_group']].corr()\n",
    "corrmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Проинтерпретируйте результаты. Можно ли им доверять, разумно ли смотреть на корреляции?* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь числовых признаков не так много, но на практике их бывают десятки, а то и сотни. В таком случае бывает полезно посмотреть на эту матрицу корреляций в виде heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт библиотек для графиков\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(corrmat, square=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К графикам надо относиться серьёзно, они должны быть понятными и информативными. Рассмотрим несколько примеров.\n",
    "\n",
    "*Прокомментируйте что вам кажется хорошим и плохим на данных графиках.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data['timestamp'])\n",
    "plt.title('Гистограмма распределения ответов по времени')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax = sns.countplot(y='fall_1', data=data)\n",
    "ax.set_title('Осенний курс по выбору, приоритет 1')\n",
    "ax.set_ylabel('')\n",
    "\n",
    "ax.set(xlabel='Количество заявок')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crs3 = data[data['17_group'].isna()]\n",
    "gr_raiting_med = crs3.groupby('18_group').median()['rating']\n",
    "gr_raiting_sum = crs3.groupby('18_group').sum()['rating']\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 6), sharex=True)\n",
    "fig.suptitle('Зависимость номера группы от рейтинга')\n",
    "#fig.text('Рейтинг')\n",
    "\n",
    "\n",
    "axs[0].plot(gr_raiting_sum)\n",
    "axs[0].set_ylabel('Суммарный рейтинг')\n",
    "\n",
    "axs[1].plot(gr_raiting_med)\n",
    "axs[1].set_ylabel('Медианный рейтинг')\n",
    "\n",
    "\n",
    "plt.xlabel('Номер группы')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы будете делать графики без подписанных осей, с налезающими друг на друга метками, неаккуратными линиями и т.д., то имеете все шансы попасть сюда: https://t.me/funny_homeworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним полученную таблицу, чтобы вы могли продолжить с ней работу дома: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel('end_seminar.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разведочный анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решение любой задачи, связанной с машинным обучением, начинается с разведочного анализа данных. Перед тем, как строить модели, надо понять, сколько у нас данных и какая информация есть о каждом объекте, а также:\n",
    "* выяснить, нет ли пропусков в данных (т.е. отсутствующих значений признаков у некоторых объектов)\n",
    "* выяснить, нет ли выбросов (т.е. объектов, которые очень сильно отличаются от большинства, имеют неадекватные значения признаков)\n",
    "* выяснить, нет ли повторов в данных\n",
    "* выяснить, нет ли нелогичной информации (например, если мы анализируем данные по кредитам, и видим запись, где кредит выдали пятилетнему ребёнку, то это странно)\n",
    "\n",
    "И это лишь небольшой список проблем, которые можно выявить. Помимо этого с данными нужно в целом познакомиться, чтобы понять, какие признаки там можно сделать, какие из них будут наиболее полезны.\n",
    "\n",
    "Попробуем провести такой анализ на реальной задаче предсказания продолжительности поездки на такси в Нью-Йорке: https://www.kaggle.com/c/nyc-taxi-trip-duration/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассказ во многом взят из ноутбука https://www.kaggle.com/gaborfodor/from-eda-to-the-top-lb-0-367/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [16, 10]\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные и изучим доступные нам признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget  -O 'train.csv' -q 'https://www.dropbox.com/s/en5f9nhn915cnkf/_train.csv?dl=0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смысл столбцов:\n",
    "\n",
    "* id - идентификатор поездки\n",
    "* vendor_id - код провайдера, от которого пришла информация о поездке\n",
    "* pickup_datetime - время старта поездки\n",
    "* dropoff_datetime - время окончания поездки\n",
    "* passenger_count - число пассажиров (вводится водителем)\n",
    "* pickup_longitude - долгота точки посадки\n",
    "* pickup_latitude - широта точки посадки\n",
    "* dropoff_longitude - долгота точки высадки\n",
    "* dropoff_latitude - долгота точки высадки\n",
    "* store_and_fwd_flag - равно Y, если информация о поездке какое-то время хранилась в памяти таксометра из-за отсутствия связи; иначе принимает значение N\n",
    "* trip_duration - продолжительность поездки в секундах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данных довольно много, поэтому нужно задумываться об эффективности всех вычислений. Ниже мы увидим на примере, что правильное использование возможностей pandas позволит существенно ускорить вычисления."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим внимательно на столбцы из нашей таблицы и попробуем проверить, нет ли там противоречий и проблем. Например, в голову приходят следующие вопросы:\n",
    "* можно ли считать ID уникальным идентификатором поездки, или же есть записи с одинаковыми ID?\n",
    "* есть ли где-то пропуски?\n",
    "* действительно ли столбец store_and_fwd_flag принимает только значения Y и N?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Id is unique.') if train.id.nunique() == train.shape[0] else print('oops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We do not need to worry about missing values.') if train.count().min() == train.shape[0] else print('oops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The store_and_fwd_flag has only two values {}.'.format(str(set(train.store_and_fwd_flag.unique()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на типы данных в каждом столбце."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что pandas отнёс столбцы с датами к общему типу object. Будет лучше привести их к типу datetime, чтобы использовать удобные функции для манипуляций с датами. Заодно сделаем проверку — действительно ли столбец check_trip_duration показывает продолжительность поездки, или же он входит в противоречие со столбцами pickup_datetime и dropoff_datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['pickup_datetime'] = pd.to_datetime(train.pickup_datetime)\n",
    "train.loc[:, 'pickup_date'] = train['pickup_datetime'].dt.date\n",
    "train['dropoff_datetime'] = pd.to_datetime(train.dropoff_datetime)\n",
    "train['store_and_fwd_flag'] = 1 * (train.store_and_fwd_flag.values == 'Y')\n",
    "train['check_trip_duration'] = (train['dropoff_datetime'] - train['pickup_datetime']).map(lambda x: x.total_seconds())\n",
    "duration_difference = train[np.abs(train['check_trip_duration'].values  - train['trip_duration'].values) > 1]\n",
    "print('Trip_duration and datetimes are ok.') if len(duration_difference[['pickup_datetime', 'dropoff_datetime', 'trip_duration', 'check_trip_duration']]) == 0 else print('Ooops.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё имеет смысл проверить целевую переменную trip_duration. Нет ли там выбросов? Какими по продолжительности бывают поездки? Выглядит ли распределение этой переменной осмысленно?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train['trip_duration'].values, bins=100)\n",
    "plt.xlabel('trip_duration')\n",
    "plt.ylabel('number of train records')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда в каком-то столбце распределение имеет тяжёлые хвосты или есть выбросы, обычные гистограммы не очень информативны. В этом случае может быть полезно нарисовать распределение в логарифмической шкале."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['log_trip_duration'] = np.log1p(train['trip_duration'].values)\n",
    "plt.hist(train['log_trip_duration'].values, bins=100)\n",
    "plt.xlabel('log(trip_duration)')\n",
    "plt.ylabel('number of train records')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом распределение разумное, продолжительность поездки находится примерно в следующем интервале:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"В секундах:\", np.exp(5), np.exp(9))\n",
    "print(\"В минутах:\", np.exp(5) // 60, np.exp(9) // 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самая длинная поездка (в часах):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['trip_duration'].max() // 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.trip_duration >= 979 * 3600]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это выброс. Мог сломаться таксометр, водитель мог забыть остановить поездку по каким-то причинам и т.д. В любом случае, будет странно обучаться на таких данных, обычно их выкидывают из выборки. Кандидатов на выбрасывание не так уж много — например, если взять поездки длиной 10 часа и больше, то их окажется около двух тысяч, и определённо надо выяснять, что это такое."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.trip_duration >= 10 * 3600]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем нарисовать, откуда обычно стартуют поездки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000\n",
    "city_long_border = (-74.03, -73.75)\n",
    "city_lat_border = (40.63, 40.85)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(train['pickup_longitude'].values[:N], train['pickup_latitude'].values[:N],\n",
    "              color='blue', s=1, label='train', alpha=0.1)\n",
    "plt.ylabel('latitude')\n",
    "plt.xlabel('longitude')\n",
    "plt.ylim(city_lat_border)\n",
    "plt.xlim(city_long_border)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нарисуем как следует, на карте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyleaflet import Map, Circle, LayerGroup, basemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_circles_on_map(data, latitude_column, longitude_column, color):\n",
    "    \"\"\"\n",
    "    The function draws map with circles on it.\n",
    "    The center of the map is the mean of coordinates passed in data.\n",
    "    \n",
    "    data: DataFrame that contains columns latitude_column and longitude_column\n",
    "    latitude_column: string, the name of column for latitude coordinates\n",
    "    longitude_column: string, the name of column for longitude coordinates\n",
    "    color: string, the color of circles to be drawn\n",
    "    \"\"\"\n",
    "\n",
    "    center = (data[latitude_column].mean(), data[longitude_column].mean())\n",
    "    result_map = Map(center=center, zoom=10, basemap=basemaps.Esri.NatGeoWorldMap)\n",
    "\n",
    "    circles = []\n",
    "    for _, row in data.iterrows():\n",
    "        circles.append(Circle(\n",
    "            location=(row[latitude_column], row[longitude_column]),\n",
    "            fill_color=color,\n",
    "            fill_opacity=0.2,\n",
    "            radius=300,\n",
    "            stroke=False\n",
    "        ))\n",
    "    circles_layer = LayerGroup(layers=circles)\n",
    "    result_map.add_layer(circles_layer)\n",
    "\n",
    "    return result_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_circles_on_map(train.sample(1000), \"pickup_latitude\", \"pickup_longitude\", \"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кстати, случайный ли порядок записей в таблице? Это важно понимать, например, для разбиения выборки на обучающую и тестовую части. Если порядок не является случайным, а мы отнесём к обучающей части первую половину таблицы, то есть риск, что данные в обучении и тесте будут иметь разные распределения, а значит, модель сможет хорошо работать только на одной из частей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "days_since_min_ride = (train['pickup_datetime'] - train['pickup_datetime'].min()).apply(lambda x: x.total_seconds() // (60*60*24))\n",
    "plt.plot(days_since_min_ride[::1000], 'o-')\n",
    "plt.title('Связь номера строки и времени поездки')\n",
    "plt.xlabel('Номер записи в таблице')\n",
    "plt.ylabel('Дней с момента ранней поездки')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вроде бы всё довольно случайно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем какие-нибудь признаки. Скорее всего продолжительность поездки неплохо зависит от расстояния — посчитаем его. Кстати, важно заметить, что само расстояние не может быть признаком, поскольку в тестовой выборе нет информации о пункте назначения. Но мы пока исследуем данные и, может, увидим в расстояниях что-то интересное.\n",
    "\n",
    "Можно выбрать научный подход и посчитать честное расстояние на сфере между двумя точками. Это называется [haversine distance](https://en.wikipedia.org/wiki/Haversine_formula).\n",
    "\n",
    "Можно решить, что Земля плоская, и считать стандартные расстояния. В этом случае очень неплохо подойдёт [манхэттенское расстояние](https://en.wikipedia.org/wiki/Taxicab_geometry) — оно учитывает, что машины всё-таки не летают."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_array(lat1, lng1, lat2, lng2):\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    AVG_EARTH_RADIUS = 6371  # in km\n",
    "    lat = lat2 - lat1\n",
    "    lng = lng2 - lng1\n",
    "    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n",
    "    h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d))\n",
    "    return h\n",
    "\n",
    "def dummy_manhattan_distance(lat1, lng1, lat2, lng2):\n",
    "    a = haversine_array(lat1, lng1, lat1, lng2)\n",
    "    b = haversine_array(lat1, lng1, lat2, lng1)\n",
    "    return a + b\n",
    "\n",
    "train.loc[:, 'distance_haversine'] = haversine_array(train['pickup_latitude'].values, train['pickup_longitude'].values, train['dropoff_latitude'].values, train['dropoff_longitude'].values)\n",
    "train.loc[:, 'distance_dummy_manhattan'] = dummy_manhattan_distance(train['pickup_latitude'].values, train['pickup_longitude'].values, train['dropoff_latitude'].values, train['dropoff_longitude'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обсудим немного скорость вычислений в pandas. Есть несколько способов применить функцию к каждой строке в таблице. Если вы до этого изучали преимущественно C/C++, то первое, что должно прийти вам в голову, — написать цикл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "for i in range(100):\n",
    "    train1[i, 'distance_haversine'] = haversine_array(train1['pickup_latitude'].iloc[i], \n",
    "                                                      train1['pickup_longitude'].iloc[i], \n",
    "                                                      train1['dropoff_latitude'].iloc[i], \n",
    "                                                      train1['dropoff_longitude'].iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что мы посчитали расстояния всего лишь для первых 100 записей, и это уже было не очень быстро."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно воспользоваться функцией ```apply```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "train1.iloc[:5000, :].apply(lambda x: \n",
    "                            haversine_array(x['pickup_latitude'], \n",
    "                                            x['pickup_longitude'], \n",
    "                                            x['dropoff_latitude'], \n",
    "                                            x['dropoff_longitude']),\n",
    "                            axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "За то же самое время мы успеваем обработать уже 5000 записей, а не 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но лучший способ — это векторизовать вычисления. Подробнее об этом мы будем говорить на следующих семинарах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "train.loc[:, 'distance_haversine'] = haversine_array(train['pickup_latitude'].values, train['pickup_longitude'].values, train['dropoff_latitude'].values, train['dropoff_longitude'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чуть подробнее об ускорении вычислений можно почитать здесь: https://engineering.upside.com/a-beginners-guide-to-optimizing-pandas-code-for-speed-c09ef2c6a4d6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределения расстояний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log1p(train.distance_haversine), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log1p(train.distance_dummy_manhattan), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выглядят достаточно одинаково.\n",
    "\n",
    "Поисследуем теперь связь между расстоянием и продолжительностью поездки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(train.distance_haversine[:100000], train.trip_duration[:100000], marker='o')\n",
    "plt.xlabel('haversine distance')\n",
    "plt.ylabel('trip duration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нижней части графика точки неплохо выстраиваются в линию, но ещё есть некоторое количество выбросов. Нарисуем тот же график без них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(train[train.trip_duration < 20000].distance_haversine[:100000],\n",
    "            train[train.trip_duration < 20000].trip_duration[:100000], marker='o')\n",
    "plt.xlabel('haversine distance')\n",
    "plt.ylabel('trip duration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется, тут вполне может сработать линейная регрессия!\n",
    "\n",
    "Ещё раз напомним, что расстояние не может быть признаком, его не посчитать для тестовой выборки. Но мы пока просто играемся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filtered = train[train.trip_duration < 20000]\n",
    "X = train_filtered.distance_haversine.values[:, np.newaxis]\n",
    "y = train_filtered.trip_duration.values\n",
    "\n",
    "regr = linear_model.Ridge()\n",
    "regr.fit(X, y)\n",
    "metrics.mean_absolute_error(regr.predict(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filtered = train[train.trip_duration < 20000]\n",
    "X = train_filtered.distance_dummy_manhattan.values[:, np.newaxis]\n",
    "y = train_filtered.trip_duration.values\n",
    "\n",
    "regr = linear_model.Ridge()\n",
    "regr.fit(X, y)\n",
    "metrics.mean_absolute_error(regr.predict(X), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть в среднем модель ошибается где-то на 300 секунд при предсказании продолжительности поездки. Как понять, хорошо это или плохо? Например, сравнить с качеством константной модели — например, которая всегда в качестве прогноза выдаёт медианное или среднее время поездки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_absolute_error(np.median(y) * np.ones(y.shape), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_absolute_error(np.mean(y) * np.ones(y.shape), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "bool(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Почему важно исследовать данные?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда бывает, что задача сложная, но при этом хорошего качества можно добиться с помощью простых правил. Причины могут быть разные:\n",
    "* Разметка собрана по простому правилу. Например, для задачи предсказания тональности твитов могли сделать разметку через эмодзи — тогда достаточно, скажем, добавить признак \"наличие в тексте подстроки ':)'\".\n",
    "* Задача действительно простая и не требует поиска закономерностей методами машинного обучения.\n",
    "* В данных есть утечка (leak) — то есть в признаках содержится информация, которая на самом деле не должна быть доступна при построении прогноза.\n",
    "\n",
    "Про некоторые истории с утечками можно почитать и посмотреть здесь:\n",
    "* https://dyakonov.org/2018/06/28/простые-методы-анализа-данных/\n",
    "* https://www.kaggle.com/c/the-icml-2013-whale-challenge-right-whale-redux/discussion/4865\n",
    "* https://www.youtube.com/watch?v=UOxf2P9WnK8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
